{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.75945308  8.77892061  1.71703139  1.3553879   0.51576392]\n"
     ]
    }
   ],
   "source": [
    "DataMatrix = [[5, 5, 4, 1, 1], [4, 5, 5, 0, 1], [5, 4, 5, 1, 0], [4, 5, 4, 1, 1], [0, 1, 2, 5, 5], [1, 2, 1, 4, 5]]\n",
    "DataMatrix = np.array(DataMatrix)\n",
    "\n",
    "U, sigma, VT = np.linalg.svd(DataMatrix)\n",
    "Sigma = np.zeros((6, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    Sigma[i][i] = sigma[i]\n",
    "\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{U}$ represents the latent factors associated with users, while $\\textbf{V}^T$ represents the latent factors associated with movies. Latent factors reflect the general preference of the users while $\\mathbf{\\Sigma}$ consists of the weights of these latent preference factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.98558332  5.0171235   3.99665013  1.0165784   0.9821824 ]\n",
      " [ 3.91364802  5.10256509  4.97993518  0.09930004  0.89327748]\n",
      " [ 4.95092102  4.05829386  4.98859597  1.05643814 -0.06065678]\n",
      " [ 4.17374486  4.79363348  4.0403715   0.80020294  1.2147315 ]\n",
      " [ 0.05517909  0.9344607   2.01282146  4.93654707  5.06819591]\n",
      " [ 0.91785348  2.09757003  0.98091237  4.09446399  4.89847501]]\n",
      "\n",
      "[[5 5 4 1 1]\n",
      " [4 5 5 0 1]\n",
      " [5 4 5 1 0]\n",
      " [4 5 4 1 1]\n",
      " [0 1 2 5 5]\n",
      " [1 2 1 4 5]]\n"
     ]
    }
   ],
   "source": [
    "k = 4   # reduction factor\n",
    "\n",
    "U_reduced, sigma_reduced, Vt_reduced = U[:, :k], sigma[:k], VT[:, :]\n",
    "Sigma_reduced = np.zeros((k, 5))\n",
    "for i in range(k):\n",
    "    Sigma_reduced[i][i] = sigma_reduced[i]\n",
    "\n",
    "A = U_reduced @ Sigma_reduced @ Vt_reduced\n",
    "\n",
    "# print(U_reduced.shape, Sigma_reduced.shape, Vt_reduced.shape)\n",
    "# print()\n",
    "\n",
    "print(A)\n",
    "print()\n",
    "print(DataMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Predicted Ratings for UserA:\n",
      " [4.84100722 3.94708469 2.17091143 2.29230152 1.82613927]\n",
      "\n",
      "Final Predicted Ratings for UserB:\n",
      " [3.03461526 1.59832698 2.30940618 4.79840628 3.46423869]\n",
      "\n",
      "UserA is a fan of: Action movies\n",
      "UserB is a fan of: Comedy movies\n"
     ]
    }
   ],
   "source": [
    "# Function to predict ratings using iterative SVD\n",
    "def iterative_predict_ratings(new_user_ratings, original_ratings, k, max_iter=10):\n",
    "    # Initialize with the new user's ratings\n",
    "    updated_ratings = np.vstack([original_ratings, new_user_ratings])\n",
    "    \n",
    "    # Iterative prediction process\n",
    "    for iteration in range(max_iter):\n",
    "        U, sigma, VT = np.linalg.svd(updated_ratings, full_matrices=False)\n",
    "        Sigma = np.diag(sigma)\n",
    "\n",
    "        U_reduced = U[:, :k]\n",
    "        Sigma_reduced = Sigma[:k, :k]\n",
    "        VT_reduced = VT[:k, :]\n",
    "\n",
    "        predicted_ratings = np.dot(U_reduced, np.dot(Sigma_reduced, VT_reduced))\n",
    "        \n",
    "        updated_ratings[-1] = predicted_ratings[-1]\n",
    "\n",
    "    final_predicted_ratings = updated_ratings[-1]  # Last row corresponds to the new user\n",
    "    return final_predicted_ratings\n",
    "\n",
    "# UserA's known ratings: M1 = 5, M4 = 1\n",
    "userA_ratings = np.array([5, 3, 3, 1, 3])  # Initial guess for M2, M3, M5 as 3\n",
    "userA_prediction = iterative_predict_ratings(userA_ratings, A, k=4)\n",
    "\n",
    "print(\"\\nFinal Predicted Ratings for UserA:\\n\", userA_prediction)\n",
    "\n",
    "# UserB's known ratings: M2 = 1, M5 = 5\n",
    "userB_ratings = np.array([3, 1, 3, 3, 5])  # Initial guess for M1, M3, M4 as 3\n",
    "userB_prediction = iterative_predict_ratings(userB_ratings, A, k=4)\n",
    "\n",
    "print(\"\\nFinal Predicted Ratings for UserB:\\n\", userB_prediction)\n",
    "\n",
    "# Determine preferences for UserA\n",
    "action_movies_A = userA_prediction[:3]\n",
    "comedy_movies_A = userA_prediction[3:]\n",
    "userA_fan = \"Action movies\" if np.mean(action_movies_A) > np.mean(comedy_movies_A) else \"Comedy movies\"\n",
    "\n",
    "# Determine preferences for UserB\n",
    "action_movies_B = userB_prediction[:3]\n",
    "comedy_movies_B = userB_prediction[3:]\n",
    "userB_fan = \"Action movies\" if np.mean(action_movies_B) > np.mean(comedy_movies_B) else \"Comedy movies\"\n",
    "\n",
    "print(f\"\\nUserA is a fan of: {userA_fan}\")\n",
    "print(f\"UserB is a fan of: {userB_fan}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vector x:\n",
      " [ 1.25499487 -0.84498171 -3.12260739 -0.7245698   3.08815706 -0.34434029\n",
      " -2.39322812  2.25508162  1.69858822 -3.67720302]\n"
     ]
    }
   ],
   "source": [
    "# Function that computes the matrix-vector product A * p without storing A\n",
    "def matrix_vector_product(p):\n",
    "    n = len(p)\n",
    "    result = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        result[i] += 2 * (i + 1)**2 * p[i]  # for diagonal\n",
    "        if i > 0:\n",
    "            result[i] += (2 * (i + 2)**2 + i**2) * p[i - 1]  # Lower diagonal\n",
    "        if i < n - 1:\n",
    "            result[i] += ((i + 1)**2 + (i + 3)**2) * p[i + 1]  # Upper diagonal\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Conjugate Gradient Method\n",
    "def conjugate_gradient(b, x0=None, tol=1e-8, max_iter=1000):\n",
    "    n = 10\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(n)  # Initial guess\n",
    "    \n",
    "    r = b - matrix_vector_product(x0)           # Residual\n",
    "    p = r.copy()\n",
    "    x = x0.copy()\n",
    "    \n",
    "    rk_dot = np.dot(r, r)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        Ap = matrix_vector_product(p)\n",
    "        alpha = rk_dot / np.dot(p, Ap)\n",
    "        \n",
    "        # Update the solution x\n",
    "        x += alpha * p\n",
    "        \n",
    "        # Update residual\n",
    "        r -= alpha * Ap\n",
    "        \n",
    "        rkp1_dot = np.dot(r, r)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.sqrt(rkp1_dot) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update the search direction\n",
    "        beta = rkp1_dot / rk_dot\n",
    "        p = r + beta * p\n",
    "        \n",
    "        rk_dot = rkp1_dot\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Vector b as defined in the problem\n",
    "b = np.zeros(10)\n",
    "for i in range(10):\n",
    "    b[i] = (i + 1) / 2.0\n",
    "\n",
    "# Solve using the Conjugate Gradient Method\n",
    "x = conjugate_gradient(b)\n",
    "\n",
    "# Print the solution\n",
    "print(\"Solution vector x:\\n\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vector x using numpy:\n",
      " [ 0.02618956  0.04476209  0.00721508 -0.00709725  0.03464274  0.01881651\n",
      " -0.02615845  0.02290478  0.04016843 -0.03987201]\n"
     ]
    }
   ],
   "source": [
    "# Matrix construction\n",
    "A = np.zeros((10, 10))\n",
    "for i in range(10):\n",
    "    A[i][i] = 2 * (i + 1) ** 2      # for i = j\n",
    "    if i > 0:\n",
    "        A[i][i - 1] = 2 * (i + 2) ** 2 + (i) ** 2           # for i = j + 1\n",
    "    if i < 9:\n",
    "        A[i][i + 1] = (i + 1) ** 2 + (i + 3) ** 2           # for i + 1 = j \n",
    "# print(A)\n",
    "\n",
    "# Vector b as defined in the problem\n",
    "b = np.zeros(10)\n",
    "for i in range(10):\n",
    "    b[i] = (i + 1) / 2.0\n",
    "# print(b)\n",
    "\n",
    "# Solving using numpy\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"Solution vector x using numpy:\\n\", x)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vecotr x using scipy:\n",
      " [-0.83568122  0.47028927  2.52366284  0.67933209 -0.14508061 -2.19994619\n",
      "  1.67186345  0.31764905 -0.94163439  1.33557458]\n",
      "\n",
      "SciPy's Conjugate Gradient method did not converge.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import cg\n",
    "\n",
    "# Solve using SciPy's Conjugate Gradient Method\n",
    "x_scipy, info = cg(A, b)\n",
    "print(\"Solution vecotr x using scipy:\\n\", x_scipy)\n",
    "\n",
    "# Check if the solver converged (info == 0 means successful convergence)\n",
    "if info == 0:\n",
    "    print(\"\\nSciPy's Conjugate Gradient method converged successfully.\")\n",
    "else:\n",
    "    print(\"\\nSciPy's Conjugate Gradient method did not converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be clealy seen, all the three solutions are different with Conjugate Gradient Descent **not converging** to the optimal solution when using scipy. This is expected seeing that the matrix A is not symmetric. Below is the implementation of the three methods when A is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vector x:\n",
      " [-0.06295363  0.06259073  0.05644052 -0.0225807   0.01545394  0.03920946\n",
      " -0.00966672  0.00404918  0.02889256 -0.00418148]\n",
      "Solution vector x using numpy:\n",
      " [-0.06295363  0.06259073  0.05644052 -0.0225807   0.01545394  0.03920946\n",
      " -0.00966672  0.00404918  0.02889256 -0.00418148]\n",
      "Solution vector x using scipy:\n",
      " [-0.06295363  0.06259073  0.05644052 -0.0225807   0.01545394  0.03920946\n",
      " -0.00966672  0.00404918  0.02889256 -0.00418148]\n",
      "\n",
      "SciPy's Conjugate Gradient method converged successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function that computes the matrix-vector product A * p without storing A\n",
    "def matrix_vector_product(p):\n",
    "    n = len(p)\n",
    "    result = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        result[i] += 2 * (i + 1)**2 * p[i]  # for diagonal\n",
    "        if i > 0:\n",
    "            result[i] += ((i + 2)**2 + i**2) * p[i - 1]  # Lower diagonal\n",
    "        if i < n - 1:\n",
    "            result[i] += ((i + 1)**2 + (i + 3)**2) * p[i + 1]  # Upper diagonal\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Conjugate Gradient Method\n",
    "def conjugate_gradient(b, x0=None, tol=1e-8, max_iter=1000):\n",
    "    n = 10\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(n)  # Initial guess\n",
    "    \n",
    "    r = b - matrix_vector_product(x0)           # Residual\n",
    "    p = r.copy()\n",
    "    x = x0.copy()\n",
    "    \n",
    "    rk_dot = np.dot(r, r)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        Ap = matrix_vector_product(p)\n",
    "        alpha = rk_dot / np.dot(p, Ap)\n",
    "        \n",
    "        # Update the solution x\n",
    "        x += alpha * p\n",
    "        \n",
    "        # Update residual\n",
    "        r -= alpha * Ap\n",
    "        \n",
    "        rkp1_dot = np.dot(r, r)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.sqrt(rkp1_dot) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update the search direction\n",
    "        beta = rkp1_dot / rk_dot\n",
    "        p = r + beta * p\n",
    "        \n",
    "        rk_dot = rkp1_dot\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Vector b as defined in the problem\n",
    "b = np.zeros(10)\n",
    "for i in range(10):\n",
    "    b[i] = (i + 1) / 2.0\n",
    "\n",
    "# Solve using the Conjugate Gradient Method\n",
    "x = conjugate_gradient(b)\n",
    "\n",
    "# Print the solution\n",
    "print(\"Solution vector x:\\n\", x)\n",
    "\n",
    "############################==============================############################\n",
    "# Matrix construction\n",
    "A = np.zeros((10, 10))\n",
    "for i in range(10):\n",
    "    A[i][i] = 2 * (i + 1) ** 2      # for i = j\n",
    "    if i > 0:\n",
    "        A[i][i - 1] = (i + 2) ** 2 + (i) ** 2           # for i = j + 1\n",
    "    if i < 9:\n",
    "        A[i][i + 1] = (i + 1) ** 2 + (i + 3) ** 2           # for i + 1 = j \n",
    "# print(A)\n",
    "\n",
    "# Vector b as defined in the problem\n",
    "b = np.zeros(10)\n",
    "for i in range(10):\n",
    "    b[i] = (i + 1) / 2.0\n",
    "# print(b)\n",
    "\n",
    "# Solving using numpy\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"Solution vector x using numpy:\\n\", x)  \n",
    "\n",
    "############################==============================############################\n",
    "\n",
    "from scipy.sparse.linalg import cg\n",
    "\n",
    "# Solve using SciPy's Conjugate Gradient Method\n",
    "x_scipy, info = cg(A, b)\n",
    "print(\"Solution vector x using scipy:\\n\", x_scipy)  \n",
    "\n",
    "# Check if the solver converged (info == 0 means successful convergence)\n",
    "if info == 0:\n",
    "    print(\"\\nSciPy's Conjugate Gradient method converged successfully.\")\n",
    "else:\n",
    "    print(\"\\nSciPy's Conjugate Gradient method did not converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is clear that the three methods yeild the same solution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
